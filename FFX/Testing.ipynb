{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocess import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from scipy.sparse import csr_matrix\n",
    "#from scoop import futures\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Split my data in 3 set with same size: Train, Test, and Validation.\n",
    "# Train and Validation are used in the fitness function, after all, the Test dataset is used to evaluate the best individual\n",
    "features, labels = load_svmlight_file(\"./data/data\")\n",
    "\n",
    "\n",
    "x, X_test, y, y_test = train_test_split(features, labels, test_size=0.3333, random_state=42, stratify=labels)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(x, y, test_size=0.5, train_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "# Classifier instance\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Store fitness evolution\n",
    "graph = []\n",
    "# Store features\n",
    "num_features = []\n",
    "\n",
    "### Functions\n",
    "\n",
    "def run_classifier(_X_train, _X_test, _y_test):\n",
    "    \"\"\"\n",
    "    Execute the classifier\n",
    "    \"\"\"\n",
    "    model = clf.fit(_X_train, y_train)\n",
    "    predictions = clf.predict(_X_test) \n",
    "    score = clf.score(_X_test, _y_test)\n",
    "    probas = clf.predict_proba(_X_test)\n",
    "\n",
    "    return predictions, probas, score\n",
    "\n",
    "def select_idx(individual):\n",
    "    \"\"\"\n",
    "    Get the indexes with 1 (ones) from a individual - this means what features were selected\n",
    "    \"\"\"\n",
    "    return np.array(individual).nonzero()[0].tolist()\n",
    "\n",
    "def select_features(columns, dataset):\n",
    "    \"\"\"\n",
    "    Filter the dataset only the features selected\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(dataset.toarray())\n",
    "    return csr_matrix(pd.DataFrame(df, columns=columns))\n",
    "\n",
    "def evaluate(individual, _x_test, _y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the dataset with the feature set selected\n",
    "    \"\"\"\n",
    "    columns = select_idx(individual)\n",
    "    return run_classifier(select_features(columns, X_train), select_features(columns, _x_test), _y_test)\n",
    "\n",
    "def evalOneMax(individual):\n",
    "    \"\"\"\n",
    "    Fitness function\n",
    "    \"\"\"\n",
    "    predictions, probas, score = evaluate(individual, X_cv, y_cv)\n",
    "    return score,\n",
    "\n",
    "def store_fitness(pop):\n",
    "    logging.debug(\"--- Fitness ---\")\n",
    "    length = len(pop)\n",
    "    # Gather all the fitnesses in one list and logging.debug the stats\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "            \n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "            \n",
    "    logging.debug(\"  Min %s\" % min(fits))\n",
    "    logging.debug(\"  Max %s\" % max(fits))\n",
    "    logging.debug(\"  Avg %s\" % mean)\n",
    "    logging.debug(\"  Std %s\" % std)\n",
    "    \n",
    "    graph.append(max(fits))\n",
    "\n",
    "def store_features(pop):\n",
    "    logging.debug(\"--- Features ---\")\n",
    "    length = len(pop)\n",
    "    nf = [np.count_nonzero(ind) for ind in pop]\n",
    "    \n",
    "    mean = sum(nf) / length\n",
    "    sum2 = sum(x*x for x in nf)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "            \n",
    "    logging.debug(\"  Min %s\" % min(nf))\n",
    "    logging.debug(\"  Max %s\" % max(nf))\n",
    "    logging.debug(\"  Avg %s\" % mean)\n",
    "    logging.debug(\"  Std %s\" % std)\n",
    "    num_features.append(max(nf))\n",
    "\n",
    "### DEAP CONFIGUTATION ###\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, 132)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Operator registering\n",
    "toolbox.register(\"evaluate\", evalOneMax)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# SCOOP\n",
    "#toolbox.register(\"map\", futures.map)\n",
    "def main(POP, CXPB, MUTPB, DATFILE):\n",
    "    random.seed(64)\n",
    "\n",
    "    # Process Pool of 4 workers\n",
    "    #pool = multiprocessing.Pool(processes=2)\n",
    "    pool = Pool(processes=4)\n",
    "    toolbox.register(\"map\", pool.map)\n",
    "\n",
    "    ## population size\n",
    "    pop = toolbox.population(n=args.pop)\n",
    "\n",
    "    ## Probabilities for Crossover, Mutation and number of generations (iterations)\n",
    "    NGEN = 300\n",
    "\n",
    "    logging.debug(\"Start of evolution\")\n",
    "\n",
    "    # Evaluate the entire population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    logging.debug(\"  Evaluated %i individuals\" % len(pop))\n",
    "\n",
    "    # Begin the evolution\n",
    "    for g in range(NGEN):\n",
    "        logging.debug(\"\\n-- Generation %i --\" % g)\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "\n",
    "        # Clone the selected individuals\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        # Apply crossover and mutation on the offspring\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < args.cros:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            if random.random() < args.mut:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "\n",
    "        #invalid_ind = [ind for ind in offspring]\n",
    "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            #logging.debug(\"Ind: {} - Fit: {}\".format(ind, fit))\n",
    "\n",
    "        logging.debug(\"  Evaluated %i individuals\" % len(invalid_ind))\n",
    "\n",
    "        # The population is entirely replaced by the offspring\n",
    "        pop[:] = offspring\n",
    "\n",
    "        #store_fitness(pop)\n",
    "        #store_features(pop)\n",
    "\n",
    "    logging.debug(\"-- End of (successful) evolution --\")\n",
    "\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    logging.debug(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
    "\n",
    "    predictions, probas, score = evaluate(best_ind, X_test, y_test)\n",
    "\n",
    "    logging.debug(\"Test score: {} - N. features selected: {}\".format(score, np.count_nonzero(best_ind)))\n",
    "\n",
    "    # line =plt.plot(graph)\n",
    "    # plt.show()\n",
    "\n",
    "    # line =plt.plot(num_features)\n",
    "    # plt.show()\n",
    "\n",
    "    with open(args.datfile, 'w') as f:\n",
    "        f.write(str(score*100))\n",
    "\n",
    "    pool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import gp\n",
    "import argparse\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocess import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import operator\n",
    "import math\n",
    "\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from scipy.sparse import csr_matrix\n",
    "#from scoop import futures\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Classifier instance\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Score - Return the mean accuracy on the given test data and labels.\n",
    "def run_classifier(_X_train, _X_test, _y_test):\n",
    "    \"\"\"\n",
    "    Execute the classifier\n",
    "    \"\"\"\n",
    "    model = clf.fit(_X_train, y_train)\n",
    "    predictions = clf.predict(_X_test)\n",
    "    score = clf.score(_X_test, _y_test)\n",
    "    probas = clf.predict_proba(_X_test)\n",
    "\n",
    "    return predictions, probas, score\n",
    "\n",
    "def select_idx(individual):\n",
    "    \"\"\"\n",
    "    Get the indexes with 1 (ones) from a individual - this means what features were selected\n",
    "    \"\"\"\n",
    "    return np.array(individual).nonzero()[0].tolist()\n",
    "\n",
    "def select_features(columns, dataset):\n",
    "    \"\"\"\n",
    "    Filter the dataset only the features selected\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(dataset.to_numpy())\n",
    "    return csr_matrix(pd.DataFrame(df, columns=columns))\n",
    "\n",
    "def evaluate(individual, _x_test, _y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the dataset with the feature set selected\n",
    "    \"\"\"\n",
    "    columns = select_idx(individual)\n",
    "    return run_classifier(select_features(columns, X_train), select_features(columns, _x_test), _y_test)\n",
    "    \n",
    "# Define new functions\n",
    "def protectedDiv(left, right):\n",
    "    try:\n",
    "        return left / right\n",
    "    except ZeroDivisionError:\n",
    "        return 1\n",
    "\n",
    "# Create the tree\n",
    "pset = gp.PrimitiveSet(\"MAIN\", 1)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(protectedDiv, 2)\n",
    "pset.addPrimitive(operator.neg, 1)\n",
    "pset.addPrimitive(math.cos, 1)\n",
    "pset.addPrimitive(math.sin, 1)\n",
    "pset.addEphemeralConstant(\"rand101\", lambda: random.randint(-1,1))\n",
    "pset.renameArguments(ARG0='x')\n",
    "pset.renameArguments(ARG1='y')\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "\n",
    "def evalSymbReg(individual, points):\n",
    "    # Transform the tree expression in a callable function\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    # Evaluate the mean squared error between the expression\n",
    "    # and the real function : x**4 + x**3 + x**2 + x\n",
    "    sqerrors = ((func(x) - x**4 - x**3 - x**2 - x)**2 for x in points)\n",
    "    return math.fsum(sqerrors) / len(points),\n",
    "\n",
    "toolbox.register(\"evaluate\", evalSymbReg, points=[x/10. for x in range(-10,10)])\n",
    "toolbox.register(\"select\", tools.selAutomaticEpsilonLexicase)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9063a9f0e032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x[10:]\n",
    "y_test = y[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12095989, 0.37624443],\n",
       "       [0.8982473 , 0.80097338],\n",
       "       [0.33282662, 0.98573347],\n",
       "       [0.69277377, 0.52971678],\n",
       "       [0.55695667, 0.27353476],\n",
       "       [0.6236606 , 0.98057015],\n",
       "       [0.07736617, 0.59434975],\n",
       "       [0.28821496, 0.94882164],\n",
       "       [0.31286853, 0.13628459],\n",
       "       [0.35644116, 0.59712233]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20021821, 0.49031142, 0.5261494 , 0.33413577, 0.19246305,\n",
       "       0.55265114, 0.30491149, 0.50323232, 0.09942915, 0.33420528])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(x, y, test_size=0.5, train_size=0.5, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69277377, 0.52971678],\n",
       "       [0.93530195, 0.90723356],\n",
       "       [0.0249123 , 0.76775584],\n",
       "       [0.35644116, 0.59712233],\n",
       "       [0.89912945, 0.16464876],\n",
       "       [0.33282662, 0.98573347],\n",
       "       [0.4593773 , 0.69866791],\n",
       "       [0.12095989, 0.37624443],\n",
       "       [0.55695667, 0.27353476],\n",
       "       [0.86619883, 0.48250919]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47276183, 0.81994288],\n",
       "       [0.28821496, 0.94882164],\n",
       "       [0.6236606 , 0.98057015],\n",
       "       [0.25162136, 0.66753129],\n",
       "       [0.33454912, 0.91309349],\n",
       "       [0.72581005, 0.67395144],\n",
       "       [0.8982473 , 0.80097338],\n",
       "       [0.60600948, 0.0762569 ],\n",
       "       [0.31286853, 0.13628459],\n",
       "       [0.07736617, 0.59434975]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33413577, 0.54714697, 0.38636915, 0.33420528, 0.17223733,\n",
       "       0.5261494 , 0.39527168, 0.20021821, 0.19246305, 0.32787448])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45724762, 0.50323232, 0.55265114, 0.35892778, 0.49000165,\n",
       "       0.40955672, 0.49031142, 0.0987294 , 0.09942915, 0.30491149])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-063baf279538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_validate_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "# This creates a dataset from https://newbedev.com/how-to-split-data-into-3-sets-train-validation-and-test\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "    \n",
    "np.random.seed([3,1415])\n",
    "df = pd.DataFrame(np.random.rand(10, 5), columns=list('ABCDE'))\n",
    "train, validate, test = train_validate_test_split(df)\n",
    "\n",
    "x, X_test, y, y_test = train_test_split(xtrain,labels,test_size=0.2,train_size=0.8)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.25,train_size =0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GAMETES_Epistasis_2_Way_1000atts_0.4H_EDM_1_EDM_1_1', 'GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1', 'GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1', 'GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001', 'GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001', 'Hill_Valley_with_noise', 'Hill_Valley_without_noise', 'adult', 'agaricus_lepiota', 'allbp', 'allhyper', 'allhypo', 'allrep', 'analcatdata_aids', 'analcatdata_asbestos', 'analcatdata_authorship', 'analcatdata_bankruptcy', 'analcatdata_boxing1', 'analcatdata_boxing2', 'analcatdata_creditscore', 'analcatdata_cyyoung8092', 'analcatdata_cyyoung9302', 'analcatdata_dmft', 'analcatdata_fraud', 'analcatdata_germangss', 'analcatdata_happiness', 'analcatdata_japansolvent', 'analcatdata_lawsuit', 'ann_thyroid', 'appendicitis', 'australian', 'auto', 'backache', 'balance_scale', 'biomed', 'breast', 'breast_cancer', 'breast_cancer_wisconsin', 'breast_w', 'buggyCrx', 'bupa', 'calendarDOW', 'car', 'car_evaluation', 'cars', 'chess', 'churn', 'clean1', 'clean2', 'cleve', 'cleveland', 'cleveland_nominal', 'cloud', 'cmc', 'coil2000', 'colic', 'collins', 'confidence', 'connect_4', 'contraceptive', 'corral', 'credit_a', 'credit_g', 'crx', 'dermatology', 'diabetes', 'dis', 'dna', 'ecoli', 'fars', 'flags', 'flare', 'german', 'glass', 'glass2', 'haberman', 'hayes_roth', 'heart_c', 'heart_h', 'heart_statlog', 'hepatitis', 'horse_colic', 'house_votes_84', 'hungarian', 'hypothyroid', 'ionosphere', 'iris', 'irish', 'kddcup', 'kr_vs_kp', 'krkopt', 'labor', 'led24', 'led7', 'letter', 'lupus', 'lymphography', 'magic', 'mfeat_factors', 'mfeat_fourier', 'mfeat_karhunen', 'mfeat_morphological', 'mfeat_pixel', 'mfeat_zernike', 'mnist', 'mofn_3_7_10', 'molecular_biology_promoters', 'monk1', 'monk2', 'monk3', 'movement_libras', 'mushroom', 'mux6', 'new_thyroid', 'nursery', 'optdigits', 'page_blocks', 'parity5', 'parity5+5', 'pendigits', 'penguins', 'phoneme', 'pima', 'poker', 'postoperative_patient_data', 'prnn_crabs', 'prnn_fglass', 'prnn_synth', 'profb', 'ring', 'saheart', 'satimage', 'schizo', 'segmentation', 'shuttle', 'sleep', 'solar_flare_1', 'solar_flare_2', 'sonar', 'soybean', 'spambase', 'spect', 'spectf', 'splice', 'tae', 'texture', 'threeOf9', 'tic_tac_toe', 'tokyo1', 'twonorm', 'vehicle', 'vote', 'vowel', 'waveform_21', 'waveform_40', 'wdbc', 'wine_quality_red', 'wine_quality_white', 'wine_recognition', 'xd6', 'yeast']\n",
      "\n",
      "['1027_ESL', '1028_SWD', '1029_LEV', '1030_ERA', '1089_USCrime', '1096_FacultySalaries', '1191_BNG_pbc', '1193_BNG_lowbwt', '1196_BNG_pharynx', '1199_BNG_echoMonths', '1201_BNG_breastTumor', '1203_BNG_pwLinear', '1595_poker', '192_vineyard', '195_auto_price', '197_cpu_act', '201_pol', '207_autoPrice', '210_cloud', '215_2dplanes', '218_house_8L', '225_puma8NH', '227_cpu_small', '228_elusage', '229_pwLinear', '230_machine_cpu', '294_satellite_image', '344_mv', '4544_GeographicalOriginalofMusic', '485_analcatdata_vehicle', '503_wind', '505_tecator', '519_vinnie', '522_pm10', '523_analcatdata_neavote', '527_analcatdata_election2000', '529_pollen', '537_houses', '542_pollution', '547_no2', '556_analcatdata_apnea2', '557_analcatdata_apnea1', '560_bodyfat', '561_cpu', '562_cpu_small', '564_fried', '573_cpu_act', '574_house_16H', '579_fri_c0_250_5', '581_fri_c3_500_25', '582_fri_c1_500_25', '583_fri_c1_1000_50', '584_fri_c4_500_25', '586_fri_c3_1000_25', '588_fri_c4_1000_100', '589_fri_c2_1000_25', '590_fri_c0_1000_50', '591_fri_c1_100_10', '592_fri_c4_1000_25', '593_fri_c1_1000_10', '594_fri_c2_100_5', '595_fri_c0_1000_10', '596_fri_c2_250_5', '597_fri_c2_500_5', '598_fri_c0_1000_25', '599_fri_c2_1000_5', '601_fri_c1_250_5', '602_fri_c3_250_10', '603_fri_c0_250_50', '604_fri_c4_500_10', '605_fri_c2_250_25', '606_fri_c2_1000_10', '607_fri_c4_1000_50', '608_fri_c3_1000_10', '609_fri_c0_1000_5', '611_fri_c3_100_5', '612_fri_c1_1000_5', '613_fri_c3_250_5', '615_fri_c4_250_10', '616_fri_c4_500_50', '617_fri_c3_500_5', '618_fri_c3_1000_50', '620_fri_c1_1000_25', '621_fri_c0_100_10', '622_fri_c2_1000_50', '623_fri_c4_1000_10', '624_fri_c0_100_5', '626_fri_c2_500_50', '627_fri_c2_500_10', '628_fri_c3_1000_5', '631_fri_c1_500_5', '633_fri_c0_500_25', '634_fri_c2_100_10', '635_fri_c0_250_10', '637_fri_c1_500_50', '641_fri_c1_500_10', '643_fri_c2_500_25', '644_fri_c4_250_25', '645_fri_c3_500_50', '646_fri_c3_500_10', '647_fri_c1_250_10', '648_fri_c1_250_50', '649_fri_c0_500_5', '650_fri_c0_500_50', '651_fri_c0_100_25', '653_fri_c0_250_25', '654_fri_c0_500_10', '656_fri_c1_100_5', '657_fri_c2_250_10', '658_fri_c3_250_25', '659_sleuth_ex1714', '663_rabe_266', '665_sleuth_case2002', '666_rmftsa_ladata', '678_visualizing_environmental', '687_sleuth_ex1605', '690_visualizing_galaxy', '695_chatfield_4', '706_sleuth_case1202', '712_chscase_geyser1', 'banana', 'titanic']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from pmlb import fetch_data, classification_dataset_names, regression_dataset_names\n",
    "\n",
    "logit_test_scores = []\n",
    "gnb_test_scores = []\n",
    "\n",
    "print(classification_dataset_names)\n",
    "print('')\n",
    "print(regression_dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = fetch_data('207_autoPrice', return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(x, y, test_size=0.5, train_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                oz1           oz2           oz3           oz4           oz5  \\\n",
      "count  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
      "mean   3.645197e-09  2.831221e-10 -5.451497e-09 -1.735985e-09 -1.040287e-09   \n",
      "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
      "min   -2.357685e+00 -1.681898e+00 -1.970431e+00 -1.630881e+00 -1.641150e+00   \n",
      "25%   -7.788459e-01 -8.424280e-01 -7.479277e-01 -8.418980e-01 -7.449293e-01   \n",
      "50%   -3.805557e-02  4.388335e-02 -1.382825e-01 -9.828104e-03 -1.903547e-01   \n",
      "75%    8.103617e-01  8.395882e-01  5.983409e-01  9.393843e-01  4.415072e-01   \n",
      "max    2.136381e+00  1.752596e+00  3.165987e+00  1.717576e+00  4.297223e+00   \n",
      "\n",
      "                oz6           oz7           oz8           oz9          oz10  \\\n",
      "count  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
      "mean  -4.768372e-10 -2.256595e-09 -2.207235e-10 -6.197952e-10 -1.158565e-09   \n",
      "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
      "min   -2.097835e+00 -1.679249e+00 -1.709652e+00 -1.700753e+00 -1.730735e+00   \n",
      "25%   -7.930967e-01 -8.486483e-01 -7.951346e-01 -8.510309e-01 -8.547635e-01   \n",
      "50%   -1.360928e-01 -3.135836e-02 -4.134383e-02  5.931182e-02  3.136426e-02   \n",
      "75%    6.605624e-01  8.806972e-01  9.691249e-01  8.846918e-01  8.537692e-01   \n",
      "max    2.851043e+00  1.751326e+00  1.559566e+00  1.699772e+00  1.666967e+00   \n",
      "\n",
      "       ...          oz17          oz18          oz19          oz20  \\\n",
      "count  ...  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
      "mean   ...  3.719702e-09  1.641922e-09  5.876645e-10 -2.350658e-09   \n",
      "std    ...  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
      "min    ... -1.758776e+00 -1.695519e+00 -1.619307e+00 -1.710305e+00   \n",
      "25%    ... -8.216727e-01 -8.463678e-01 -8.964478e-01 -9.211217e-01   \n",
      "50%    ...  8.799705e-03 -5.814490e-02 -7.903413e-02  6.418638e-02   \n",
      "75%    ...  7.664708e-01  8.616143e-01  8.098935e-01  8.383731e-01   \n",
      "max    ...  1.769792e+00  1.725825e+00  1.794122e+00  1.645671e+00   \n",
      "\n",
      "               oz21          oz22          oz23          oz24          oz25  \\\n",
      "count  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
      "mean  -1.870329e-09 -2.767891e-09  6.924383e-10 -2.413988e-09 -2.257526e-09   \n",
      "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
      "min   -1.780263e+00 -1.658689e+00 -1.714237e+00 -1.655560e+00 -1.636391e+00   \n",
      "25%   -8.169543e-01 -8.694670e-01 -8.812304e-01 -9.269826e-01 -8.134955e-01   \n",
      "50%    4.580752e-02  3.379012e-02 -3.797246e-03  1.375743e-01 -1.325607e-01   \n",
      "75%    8.964547e-01  8.198601e-01  9.404481e-01  8.083181e-01  8.175431e-01   \n",
      "max    1.689198e+00  1.728174e+00  1.762821e+00  1.678338e+00  1.862283e+00   \n",
      "\n",
      "             target  \n",
      "count  2.500000e+02  \n",
      "mean  -1.110835e-09  \n",
      "std    1.000000e+00  \n",
      "min   -2.565029e+00  \n",
      "25%   -6.316575e-01  \n",
      "50%    6.634237e-02  \n",
      "75%    6.885833e-01  \n",
      "max    3.222853e+00  \n",
      "\n",
      "[8 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "var = fetch_data('644_fri_c4_250_25')\n",
    "print(var.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.15000000e+02, 9.88000031e+01, ...,\n",
       "        4.80000000e+03, 2.60000000e+01, 3.20000000e+01],\n",
       "       [2.00000000e+00, 9.40000000e+01, 9.73000031e+01, ...,\n",
       "        4.80000000e+03, 3.70000000e+01, 4.60000000e+01],\n",
       "       [0.00000000e+00, 1.02000000e+02, 9.70000000e+01, ...,\n",
       "        4.80000000e+03, 2.40000000e+01, 2.90000000e+01],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.48000000e+02, 9.36999969e+01, ...,\n",
       "        5.50000000e+03, 3.10000000e+01, 3.80000000e+01],\n",
       "       [2.00000000e+00, 1.04000000e+02, 9.90999985e+01, ...,\n",
       "        5.25000000e+03, 2.10000000e+01, 2.80000000e+01],\n",
       "       [0.00000000e+00, 1.02000000e+02, 9.71999969e+01, ...,\n",
       "        5.20000000e+03, 2.60000000e+01, 3.20000000e+01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2a6edf7316eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclassification_dataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassification_dataset_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_samples_seen_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         X = self._validate_data(X, reset=first_pass,\n\u001b[0m\u001b[1;32m    370\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                                 force_all_finite=\"allow-nan\")\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from pmlb import fetch_data, classification_dataset_names\n",
    "\n",
    "logit_test_scores = []\n",
    "gnb_test_scores = []\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for classification_dataset in classification_dataset_names:\n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    train_X, test_X, train_y, test_y = min_max_scaler.fit_transform(train_test_split(X, y))\n",
    "\n",
    "    logit = LogisticRegression()\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    logit.fit(train_X, train_y)\n",
    "    gnb.fit(train_X, train_y)\n",
    "\n",
    "    logit_test_scores.append(logit.score(test_X, test_y))\n",
    "    gnb_test_scores.append(gnb.score(test_X, test_y))\n",
    "\n",
    "sb.boxplot(data=[logit_test_scores, gnb_test_scores], notch=True)\n",
    "plt.xticks([0, 1], ['LogisticRegression', 'GaussianNB'])\n",
    "plt.ylabel('Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
