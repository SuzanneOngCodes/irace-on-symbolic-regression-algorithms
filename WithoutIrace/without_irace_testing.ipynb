{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import operator\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import graphviz\n",
    "from collections import OrderedDict\n",
    "from sympy import simplify\n",
    "\n",
    "# For Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# For Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# For GPLearn\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from gplearn.functions import make_function\n",
    "\n",
    "# For FFX estimator\n",
    "import ffx\n",
    "\n",
    "# For QLattice\n",
    "import feyn\n",
    "# ql = feyn.connect_qlattice()\n",
    "\n",
    "# For DEAP\n",
    "# from tpot import TPOTRegressor\n",
    "\n",
    "from pyshgp.push.instruction_set import InstructionSet\n",
    "from pyshgp.gp.estimators import PushEstimator\n",
    "from pyshgp.gp.genome import GeneSpawner\n",
    "\n",
    "# Checks time\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Number of observations</th>\n",
       "      <th>Number of features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body_fat.csv</td>\n",
       "      <td>252</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hill_Valley_with_noise.csv</td>\n",
       "      <td>1212</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allbp.csv</td>\n",
       "      <td>3772</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analcatdata_cyyoung9302.csv</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>229_pwLinear.csv</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          File  Number of observations  Number of features\n",
       "0                 body_fat.csv                     252                  14\n",
       "1   Hill_Valley_with_noise.csv                    1212                 100\n",
       "2                    allbp.csv                    3772                  29\n",
       "3  analcatdata_cyyoung9302.csv                      92                  10\n",
       "4             229_pwLinear.csv                     200                  10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read compiled dataset with number of features and observations on the 50 assigned datasets\n",
    "df = pd.read_csv(\"../Datasets/All_Datasets_Stats.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic implementation of regression systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    26.15      7.12135e+55       63         0.486899         0.602664     21.66s\n",
      "   1     4.52      1.58945e+38        3         0.494102         0.576471     14.11s\n",
      "   2     2.93          889.644        5         0.482453          0.65312     14.67s\n",
      "   3     2.41          774.002        3         0.486239         0.647059     13.51s\n",
      "   4     1.01          8.92878        3          0.48886         0.623529     12.18s\n",
      "   5     1.00           1.4802        1          1.46245          1.64159     11.78s\n",
      "   6     1.00          1.48045        1          1.46114          1.65335     11.57s\n",
      "   7     1.00          1.48062        1          1.46376          1.62982     11.00s\n",
      "   8     1.00          1.48047        1          1.46245          1.64159     10.68s\n",
      "   9     1.00          1.48036        1          1.46245          1.64159     10.43s\n",
      "  10     1.00          1.48037        1          1.46376          1.62982     10.09s\n",
      "  11     1.00          1.48063        1          1.45983          1.66512      9.79s\n",
      "  12     1.00          1.48038        1          1.46245          1.64159      9.43s\n",
      "  13     1.00          1.48032        1          1.45983          1.66512      9.07s\n",
      "  14     1.00          1.48047        1          1.46376          1.62982     46.35s\n",
      "  15     1.00           1.4805        1          1.46376          1.62982      8.62s\n",
      "  16     1.00           1.4803        1          1.46245          1.64159      8.03s\n",
      "  17     1.00          1.48022        1          1.46114          1.65335      7.70s\n",
      "  18     1.00          1.48068        1          1.46245          1.64159      7.32s\n",
      "  19     1.00          1.48038        1          1.46376          1.62982      7.00s\n",
      "  20     1.00          1.48019        1          1.45852          1.67688      6.66s\n",
      "  21     1.00          1.48052        1          1.46114          1.65335      6.53s\n",
      "  22     1.00          1.48022        1          1.46114          1.65335      6.03s\n",
      "  23     1.00          1.48014        1          1.46245          1.64159      5.67s\n",
      "  24     1.00          1.48031        1          1.46376          1.62982      5.35s\n",
      "  25     1.00          1.48006        1          1.46245          1.64159      4.94s\n",
      "  26     1.00           1.4806        1          1.46245          1.64159      4.89s\n",
      "  27     1.00           1.4804        1          1.46507          1.61806      4.26s\n",
      "  28     1.00          1.48038        1          1.46245          1.64159      3.99s\n",
      "  29     1.00          1.48041        1          1.46114          1.65335      3.65s\n",
      "  30     1.00          1.48062        1          1.46376          1.62982      3.19s\n",
      "  31     1.00          1.48046        1          1.46114          1.65335      2.86s\n",
      "  32     1.00          1.48047        1          1.46245          1.64159      2.49s\n",
      "  33     1.00           1.4806        1          1.46245          1.64159      2.48s\n",
      "  34     1.00          1.48019        1          1.46245          1.64159      1.84s\n",
      "  35     1.00           1.4804        1          1.46376          1.62982      1.47s\n",
      "  36     1.00          1.48022        1          1.46245          1.64159      1.08s\n",
      "  37     1.00          1.48025        1          1.45852          1.67688      0.71s\n",
      "  38     1.00          1.48035        1          1.45983          1.66512      0.36s\n",
      "  39     1.00          1.48039        1          1.46245          1.64159      0.00s\n"
     ]
    }
   ],
   "source": [
    "# GPLearn (Genetic Programming)\n",
    "def GP(POP, GEN, CXPB, PC):\n",
    "    est_gp = SymbolicRegressor(population_size=POP,\n",
    "                           generations=GEN,p_crossover=CXPB, p_subtree_mutation=0,\n",
    "                           p_hoist_mutation=0, p_point_mutation=0,\n",
    "                           max_samples=0.9, verbose=1,\n",
    "                           parsimony_coefficient=PC, random_state=0)\n",
    "    \n",
    "    return est_gp \n",
    "\n",
    "# Random Forest Regressor\n",
    "def RR(NUM, DEPTH, JOB, VER):\n",
    "    est_rr = RandomForestRegressor(n_estimators=NUM, max_depth=DEPTH, n_jobs= JOB, verbose=VER, random_state=0)\n",
    "    return est_rr \n",
    "\n",
    "# Support Vector Regression\n",
    "def SVR(C, EPI, CS , ITER):\n",
    "    est_svr = make_pipeline(StandardScaler(), SVR(C=C, epsilon=EPI, cache_size = CS, max_iter = ITER))\n",
    "    return est_svr \n",
    "\n",
    "df1 = pd.read_csv(\"../Datasets/Hill_Valley_with_noise.csv\")\n",
    "size = len(df1.columns)-1\n",
    "X = df1.drop(['target'], axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "# dividing X and y into training and testing units\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
    "gp = GP(1021 , 40, 0.54 , 0.73)\n",
    "gp.fit(X_train, y_train)\n",
    "y_test_pred = gp.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 3th-cv split\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/Hill_Valley_with_noise.csv\")\n",
    "import math\n",
    "        \n",
    "size = len(df.columns)-1\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# dividing X and y into training and testing units\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True, random_state=1)\n",
    "n_train = math.ceil(X.shape[0] * 0.7)\n",
    "\n",
    "X_train = X.iloc[:n_train, :]\n",
    "y_train = y.iloc[:n_train]\n",
    "\n",
    "X_test = X.iloc[n_train:, :]\n",
    "y_test = y.iloc[n_train:]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "INSTANCES = \"i4\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks time\n",
    "from time import process_time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Symbolic regression parameters\n",
    "pop = [int(x) for x in np.linspace(start = 1000, stop = 1500)]\n",
    "generation = [int(x) for x in np.linspace(start = 10, stop = 50)]\n",
    "crossover = [float(x) for x in np.linspace(0.01, 1)]\n",
    "parsimony_coefficient = [float(x) for x in np.linspace(start = 0.01, stop = 1)]\n",
    "\n",
    "# Random forest parameters\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 500)]\n",
    "n_jobs = [int(x) for x in np.linspace(start = 1, stop = 20)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 20)]\n",
    "verbose = [int(x) for x in np.linspace(start = 0, stop = 20)]\n",
    "\n",
    "# SVR parameters\n",
    "c = [int(x) for x in np.linspace(start = 1, stop = 20, num = 20)]\n",
    "epsilon = [float(x) for x in np.linspace(start = 0.1, stop = 20)]\n",
    "cache_size = [int(x) for x in np.linspace(1, 1000)]\n",
    "max_iter = [int(x) for x in np.linspace(start = 1, stop = 100)]\n",
    "\n",
    "datarr = pd.DataFrame()\n",
    "\n",
    "def calculateTime(regressor):\n",
    "#     df1 = pd.read_csv(\"../Datasets/\"+ str(df.File[i]))\n",
    "    df1 = pd.read_csv(\"../Datasets/Hill_Valley_with_noise.csv\")\n",
    "    size = len(df1.columns)-1\n",
    "    X = df1.drop(['target'], axis=1)\n",
    "    y = df1['target']\n",
    "\n",
    "    # dividing X and y into training and testing units\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=1)\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {}\n",
    "\n",
    "    if regressor == \"GPLearn\":\n",
    "        rf = SymbolicRegressor(p_subtree_mutation=0,\n",
    "                       p_hoist_mutation=0, p_point_mutation=0,\n",
    "                       max_samples=0.9, verbose=1,random_state=0)\n",
    "        random_grid = {'population_size': pop,\n",
    "                   'generations': generation,\n",
    "               'p_crossover': crossover,\n",
    "               'parsimony_coefficient': parsimony_coefficient}\n",
    "        rf_random = GridSearchCV(estimator = rf, param_grid = random_grid)\n",
    "    elif regressor == \"RR\":\n",
    "        rf = RandomForestRegressor()\n",
    "        random_grid = {'n_estimators': n_estimators,\n",
    "                   'n_jobs': n_jobs,\n",
    "                   'max_depth': max_depth,\n",
    "                   'verbose': verbose}\n",
    "        rf_random = GridSearchCV(estimator = rf, param_grid = random_grid)\n",
    "    else:\n",
    "        random_grid = {'rbf_svm__C': c,\n",
    "                   'rbf_svm__epsilon': epsilon,\n",
    "                   'rbf_svm__cache_size': cache_size,\n",
    "                   'rbf_svm__max_iter': max_iter}\n",
    "        steps = [('scaler', StandardScaler()), ('rbf_svm', SVR())]\n",
    "        pipeline = Pipeline(steps)\n",
    "        # do search\n",
    "        rf_random = GridSearchCV(pipeline, param_grid=random_grid)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "\n",
    "    return rf_random.best_params_, rf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.16635826639702408\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.05710647673039142\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.05710647673039142\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.05710647673039142\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.05710647673039142\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(Normalizer(input_matrix, norm=max), max_depth=3, min_samples_leaf=1, min_samples_split=8)\n",
      "-0.05972384415698741\n"
     ]
    }
   ],
   "source": [
    "# start = process_time()\n",
    "# bp, rf_random = calculateTime(\"GP\")\n",
    "\n",
    "\n",
    "# y_test_pred = rf_random.predict(X_test)\n",
    "# # Mean absolute error\n",
    "# mae = mean_absolute_error(y_test, y_test_pred)\n",
    "# # Mean squared error to check performance\n",
    "# mse = mean_squared_error(y_test, y_test_pred)\n",
    "# # Root mean squared error to check accuracy\n",
    "# rmse = sqrt(mse)\n",
    "\n",
    "# stop = process_time()\n",
    "# tt = stop-start\n",
    "# models = {'GPLearn Symbolic Regression': ,\n",
    "#           'Random Forest Regression': RR(),\n",
    "#           'Support Vector Regression': SVR()\n",
    "#          }\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"../Datasets/Hill_Valley_with_noise.csv\")\n",
    "size = len(df.columns)-1\n",
    "X = df1.drop(['target'], axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True, random_state=1)\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-104cbad83970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tt' is not defined"
     ]
    }
   ],
   "source": [
    "print(tt)\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt, mae, mse, rmse = calculateTime(\"GPLearn\")\n",
    "print(tt)\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SVR() missing 3 required positional arguments: 'EPI', 'CS', and 'ITER'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ab43c707fd19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c8e55179ca0d>\u001b[0m in \u001b[0;36mcalculateTime\u001b[0;34m(regressor)\u001b[0m\n\u001b[1;32m     62\u001b[0m                    \u001b[0;34m'rbf_svm__cache_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                    'rbf_svm__max_iter': max_iter}\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'rbf_svm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# do search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: SVR() missing 3 required positional arguments: 'EPI', 'CS', and 'ITER'"
     ]
    }
   ],
   "source": [
    "tt, mae, mse, rmse = calculateTime(\"SVR\")\n",
    "print(tt)\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass kernel=1, degree=1 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0144ed956830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# SVR approach\n",
    "best_SVR_non = []\n",
    "start = process_time()\n",
    "\n",
    "cur_rmse = 10000000\n",
    "\n",
    "for x in range(1,20):\n",
    "    for y in range(1,20):\n",
    "            total = SVR(x,y)\n",
    "            total.fit(X_train, y_train)\n",
    "            y_test_pred = total.predict(X_test)\n",
    "            mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            mse = mean_squared_error(y_test, y_test_pred)\n",
    "            rmse = sqrt(mse)\n",
    "            if rmse<cur_rmse:\n",
    "                best_num = x\n",
    "                best_depth = y \n",
    "                best_SVR_non = [x,y]\n",
    "stop = process_time()\n",
    "print('Time: ', stop - start)  \n",
    "\n",
    "print(best_SVR_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name, model_instance in models.items():\n",
    "#     print('Training model {}'.format(model_name))\n",
    "#     model_instance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GPLearn Symbolic Regression: \n",
      " mae: 0.6365963201245488 \n",
      " mse: 0.6062201564526084 \n",
      "rmse: 0.7786014105128557 \n",
      "\n",
      "Model Random Forest: \n",
      " mae: 0.40887500000000004 \n",
      " mse: 0.31670725000000005 \n",
      "rmse: 0.5627674919538264 \n",
      "\n",
      "Model Support Vector Regression: \n",
      " mae: 0.4735990938254245 \n",
      " mse: 0.38761639573435075 \n",
      "rmse: 0.6225884641834851 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "for model_name, model_instance in models.items():\n",
    "    y_test_pred = model_instance.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    print('Model {}: \\n mae: {} \\n mse: {} \\nrmse: {} \\n'.format(model_name, mae, mse,rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if all symbolic regression systems works\n",
    "# simplify(models[0].sympify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: To create tree diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul(sub(X3, X0), 0.140)\n"
     ]
    }
   ],
   "source": [
    "# Print fittest solution\n",
    "print(models['GPLearn Symbolic Regression']._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'result.gv.pdf'"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export to a graph instance\n",
    "graph = models['GPLearn Symbolic Regression']._program.export_graphviz()  \n",
    "graph_str = str(graph)\n",
    "program_str = str(models['GPLearn Symbolic Regression']._program)\n",
    "\n",
    "# Replace X{} with actual features names\n",
    "mapping_dict = {'X{}'.format(i): X.columns[i] for i in reversed(range(X.shape[1]))}\n",
    "for old_value, new_value in mapping_dict.items():\n",
    "    graph_str = graph_str.replace(old_value, str(new_value))\n",
    "    program_str = program_str.replace(old_value, str(new_value))\n",
    "\n",
    "    \n",
    "# Save localy\n",
    "src = graphviz.Source(graph_str)\n",
    "src.render('result.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mul(sub(oz4, oz1), 0.140)'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-288092ff30c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
